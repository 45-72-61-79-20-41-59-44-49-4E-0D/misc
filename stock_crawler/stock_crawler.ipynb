{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-03-15 10:33:34--  https://www.quandl.com/api/v3/databases/YAHOO/codes\n",
      "Resolving www.quandl.com... 54.236.186.91, 52.72.234.18\n",
      "Connecting to www.quandl.com|54.236.186.91|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://quandl-bulk-download.s3.amazonaws.com/YAHOO-datasets-codes.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAJPHL6UE63XMSB6UQ%2F20160315%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20160315T033335Z&X-Amz-Expires=30&X-Amz-Security-Token=AQoDYXdzEFQa4AMbyiUXI%2FUBoKlm7T1kUB5kjxVB3konArw%2BeUK6%2FMVihHwIKWlqJCdKuC7Iv%2FIH%2FjTK1MkET3sMEjmJuT3yoH9%2FCVHLZ7ZKGVemjpnKmpcK8P%2BtRcIuGyG3HejOth9MxIdNrpXrbooimbF16PqZv7pKyKJx%2Fc7Cjb6nFbz%2B6ecGlUW3bm2vVdtA%2FubKk%2F7jb0aygu2nKMmrnwhPavXslAAkzrXkYINqvtDimL%2B698E5P8X4RD5Bo7z7oqWxN6%2FBLAuhx4Ysh4bRqDFyzbkjyLxjNJ8Bi5QfGUn8h1eTQXJuNlWtzxlAp56KskEo1cuAN9wMby9G8qbjn%2F5u2wgR7C3Brf8mT4hTVxxNRGDqyiZXX2MSTfoU%2FKEg85L7z7%2BbDuyV8ZwocmvTpcxELhQoEsxjEWtkuSYdfmns3umyzqizi5YqHvdoxppOwiV%2Bjf6dVmmklBl%2FNzfvTezCJ0OB%2B%2FuYbgK8RBDBKAK8u1mji%2BfRIAENeJzBMSoWMmcWH8WoJYvNqvrIJydbc5caMdpodWyfmCZwos0ZbJxDGp7cxfmcBixuPTPr1J4x75PY7MFohWsFw%2B3APZBjZKU6afx8l11pDeRJ2BE9tMItqCfR7BgwxNPyED7fjOmgcDJmP6afHl0g9%2FGdtwU%3D&X-Amz-SignedHeaders=host&X-Amz-Signature=c8528fa181fa5f68e10655660f3be66f997256007177fc3ef09f3919d4d93353 [following]\n",
      "--2016-03-15 10:33:35--  https://quandl-bulk-download.s3.amazonaws.com/YAHOO-datasets-codes.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAJPHL6UE63XMSB6UQ%2F20160315%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20160315T033335Z&X-Amz-Expires=30&X-Amz-Security-Token=AQoDYXdzEFQa4AMbyiUXI%2FUBoKlm7T1kUB5kjxVB3konArw%2BeUK6%2FMVihHwIKWlqJCdKuC7Iv%2FIH%2FjTK1MkET3sMEjmJuT3yoH9%2FCVHLZ7ZKGVemjpnKmpcK8P%2BtRcIuGyG3HejOth9MxIdNrpXrbooimbF16PqZv7pKyKJx%2Fc7Cjb6nFbz%2B6ecGlUW3bm2vVdtA%2FubKk%2F7jb0aygu2nKMmrnwhPavXslAAkzrXkYINqvtDimL%2B698E5P8X4RD5Bo7z7oqWxN6%2FBLAuhx4Ysh4bRqDFyzbkjyLxjNJ8Bi5QfGUn8h1eTQXJuNlWtzxlAp56KskEo1cuAN9wMby9G8qbjn%2F5u2wgR7C3Brf8mT4hTVxxNRGDqyiZXX2MSTfoU%2FKEg85L7z7%2BbDuyV8ZwocmvTpcxELhQoEsxjEWtkuSYdfmns3umyzqizi5YqHvdoxppOwiV%2Bjf6dVmmklBl%2FNzfvTezCJ0OB%2B%2FuYbgK8RBDBKAK8u1mji%2BfRIAENeJzBMSoWMmcWH8WoJYvNqvrIJydbc5caMdpodWyfmCZwos0ZbJxDGp7cxfmcBixuPTPr1J4x75PY7MFohWsFw%2B3APZBjZKU6afx8l11pDeRJ2BE9tMItqCfR7BgwxNPyED7fjOmgcDJmP6afHl0g9%2FGdtwU%3D&X-Amz-SignedHeaders=host&X-Amz-Signature=c8528fa181fa5f68e10655660f3be66f997256007177fc3ef09f3919d4d93353\n",
      "Resolving quandl-bulk-download.s3.amazonaws.com... 54.231.97.200\n",
      "Connecting to quandl-bulk-download.s3.amazonaws.com|54.231.97.200|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1704805 (1.6M) [application/zip]\n",
      "Saving to: 'YAHOO-datasets-codes.zip'\n",
      "\n",
      "YAHOO-datasets-code 100%[=====================>]   1.62M   126KB/s   in 15s    \n",
      "\n",
      "2016-03-15 10:33:53 (110 KB/s) - 'YAHOO-datasets-codes.zip' saved [1704805/1704805]\n",
      "\n",
      "Archive:  YAHOO-datasets-codes.zip\n",
      "  inflating: YAHOO-datasets-codes.csv  \n"
     ]
    }
   ],
   "source": [
    "! wget https://www.quandl.com/api/v3/databases/YAHOO/codes -O YAHOO-datasets-codes.zip\n",
    "! unzip YAHOO-datasets-codes.zip\n",
    "! pip install Quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93389 codes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_codes = pd.read_csv('YAHOO-datasets-codes.csv', header=None, names=['code_full', 'desc'], sep=',')\n",
    "codes = sorted(df_codes.code_full.unique().tolist())\n",
    "print '{} codes'.format(len(codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download NASDAQ companies here: \n",
    "# http://www.nasdaq.com/screening/companies-by-industry.aspx?industry=ALL&exchange=NASDAQ&region=North+America&country=United+States\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "df_codes = pd.read_csv('nasdaq_companies.csv')\n",
    "codes = ['YAHOO/' + x for x in sorted(df_codes.Symbol.unique().tolist())]\n",
    "print '{} codes'.format(len(codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'YAHOO/512NTR', 'https://www.quandl.com/api/v3/datasets/YAHOO/512NTR/data.csv?order=asc&start_date=2008-01-01&end_date=2015-12-31&collapse=daily?api_key=z_qHczbyvXpHXkWjB8cz')\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['wget', 'https://www.quandl.com/api/v3/datasets/YAHOO/AAIGF/data.csv?order=asc&start_date=2008-01-01&end_date=2015-12-31&collapse=daily?api_key=z_qHczbyvXpHXkWjB8cz', '-O', './data/YAHOO_AAIGF.csv']' returned non-zero exit status 8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e30df39040b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wget'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-O'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./data/{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.10/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopenargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['wget', 'https://www.quandl.com/api/v3/datasets/YAHOO/AAIGF/data.csv?order=asc&start_date=2008-01-01&end_date=2015-12-31&collapse=daily?api_key=z_qHczbyvXpHXkWjB8cz', '-O', './data/YAHOO_AAIGF.csv']' returned non-zero exit status 8"
     ]
    }
   ],
   "source": [
    "# download\n",
    "import subprocess\n",
    "import os\n",
    "import Quandl\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def download(api_key):\n",
    "    START_DATE='2008-01-01'\n",
    "    END_DATE='2015-12-31'\n",
    "    OUTPUT_DIR = './data'\n",
    "    \n",
    "    for i, c in enumerate(codes):\n",
    "        out_file = '{}/{}.csv'.format(OUTPUT_DIR, c.replace('/', '_'))\n",
    "        if os.path.exists(out_file):\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            data = Quandl.get(c, authtoken=api_key, trim_start=START_DATE, trim_end=END_DATE, collapse='daily',\n",
    "                         sort_order='asc')\n",
    "            data.to_csv(out_file)\n",
    "        except Quandl.ErrorDownloading as e:\n",
    "            print c, e\n",
    "            time.sleep(60)\n",
    "        except Quandl.DatasetNotFound as ex:\n",
    "            print c, ex\n",
    "\n",
    "            \n",
    "API_KEYS = ['z_qHczbyvXpHXkWjB8cz', # nanda\n",
    "            'XYNex2DMWPXYJxGmMoFJ', # vupham\n",
    "            'WN4Vhr1z5AoPpMtU83ei' # phvu225\n",
    "            'VWNHCikUJsHxXbgQmu' # vu.phoai\n",
    "           ]\n",
    "p = Pool(min(5, len(API_KEYS)))\n",
    "p.map(download, API_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download anything left\n",
    "\n",
    "# filter out already downloaded\n",
    "codes = [c for c in codes if not os.path.exists('./data/{}.csv'.format(c.replace('/', '_')))]\n",
    "print '{} codes left'.format(len(codes))\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import Quandl\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "API_KEYS = ['z_qHczbyvXpHXkWjB8cz', # nanda\n",
    "            'XYNex2DMWPXYJxGmMoFJ', # vupham\n",
    "            'WN4Vhr1z5AoPpMtU83ei' # phvu225\n",
    "            'VWNHCikUJsHxXbgQmu' # vu.phoai\n",
    "           ]\n",
    "\n",
    "def download(c):\n",
    "    START_DATE='2008-01-01'\n",
    "    END_DATE='2015-12-31'\n",
    "    OUTPUT_DIR = './data'\n",
    "    \n",
    "    out_file = '{}/{}.csv'.format(OUTPUT_DIR, c.replace('/', '_'))\n",
    "    if os.path.exists(out_file):\n",
    "        return\n",
    "\n",
    "    i = 0\n",
    "    while(True):\n",
    "        try:\n",
    "            api_key = API_KEYS[i]\n",
    "            i = (i + 1) % len(API_KEYS)\n",
    "            data = Quandl.get(c, authtoken=api_key, trim_start=START_DATE, trim_end=END_DATE, collapse='daily',\n",
    "                         sort_order='asc')\n",
    "            data.to_csv(out_file)\n",
    "        except Quandl.ErrorDownloading as e:\n",
    "            print c, e\n",
    "            time.sleep(60)\n",
    "        except Quandl.DatasetNotFound as ex:\n",
    "            print 'DatasetNotFound: {}'.format(c)\n",
    "            return\n",
    "\n",
    "p = Pool(5)\n",
    "p.map(download, codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23467 codes\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "import Quandl\n",
    "import pandas as pd\n",
    "\n",
    "def download(output_dir, c):\n",
    "    API_KEYS = ['z_qHczbyvXpHXkWjB8cz', # nanda\n",
    "                'XYNex2DMWPXYJxGmMoFJ', # vupham\n",
    "                'WN4Vhr1z5AoPpMtU83ei' # phvu225\n",
    "                'VWNHCikUJsHxXbgQmu' # vu.phoai\n",
    "               ]\n",
    "    START_DATE='2008-01-01'\n",
    "    END_DATE='2015-12-31'\n",
    "\n",
    "    out_file = '{}/{}.csv'.format(output_dir, c.replace('/', '_'))\n",
    "    if os.path.exists(out_file):\n",
    "        return -1\n",
    "\n",
    "    i = 0\n",
    "    while(True):\n",
    "        try:\n",
    "            api_key = API_KEYS[i]\n",
    "            i = (i + 1) % len(API_KEYS)\n",
    "            data = Quandl.get(c, authtoken=api_key, trim_start=START_DATE, trim_end=END_DATE, collapse='daily',\n",
    "                         sort_order='asc')\n",
    "            data.to_csv(out_file)\n",
    "            return 0\n",
    "        except Quandl.ErrorDownloading as e:\n",
    "            print c, e\n",
    "            time.sleep(60)\n",
    "        except Quandl.DatasetNotFound as ex:\n",
    "            print 'DatasetNotFound: {}'.format(c)\n",
    "            return -2\n",
    "        except KeyboardInterrupt:\n",
    "            print 'KeyboardInterrupt'\n",
    "            return -3\n",
    "        \n",
    "def crawl_stocks(symbols, output_dir):\n",
    "    p = Pool(5)\n",
    "    rets = p.map(partial(download, output_dir), symbols)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    \n",
    "    print 'Downloaded {}, existed {}, dataset not found {}, interruptted {}'.format(\n",
    "        sum([x == 0 for x in rets]), sum([x == -1 for x in rets]), \n",
    "        sum([x == -2 for x in rets]), sum([x == -3 for x in rets]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# funds.csv\n",
    "funds = pd.read_csv('funds.csv')\n",
    "codes = sorted(funds['Quandl Code'].unique().tolist())\n",
    "print '{} codes'.format(len(codes))\n",
    "crawl_stocks(codes, './data_funds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nasdaq_indices.csv\n",
    "codes = sorted(pd.read_csv('nasdaq_indices.csv')['Quandl Code'].unique().tolist())\n",
    "print '{} codes'.format(len(codes))\n",
    "crawl_stocks(codes, './data_nasdaq_indices')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
